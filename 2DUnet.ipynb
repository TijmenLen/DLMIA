{"cells":[{"cell_type":"code","execution_count":null,"id":"532a126b-fe08-4103-a359-d3149d3b092c","metadata":{"tags":[],"id":"532a126b-fe08-4103-a359-d3149d3b092c","outputId":"0807bd90-3918-49d3-f1c8-bc6654f206d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: nibabel in /home/jovyan/.local/lib/python3.10/site-packages (5.3.2)\n","Requirement already satisfied: monai in /home/jovyan/.local/lib/python3.10/site-packages (1.4.0)\n","Requirement already satisfied: matplotlib in /home/jovyan/.local/lib/python3.10/site-packages (3.10.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu118)\n","Requirement already satisfied: wandb in /home/jovyan/.local/lib/python3.10/site-packages (0.19.7)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.15.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: medpy in /home/jovyan/.local/lib/python3.10/site-packages (0.5.2)\n","Requirement already satisfied: importlib-resources>=5.12 in /home/jovyan/.local/lib/python3.10/site-packages (from nibabel) (6.5.2)\n","Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from nibabel) (24.2)\n","Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from nibabel) (4.12.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /home/jovyan/.local/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/lib/python3/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/lib/python3/dist-packages (from matplotlib) (4.29.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: pillow>=8 in /home/jovyan/.local/lib/python3.10/site-packages (from matplotlib) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: filelock in /home/jovyan/.local/lib/python3.10/site-packages (from torch) (3.11.0)\n","Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch) (1.9)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch) (11.8.89)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch) (11.8.89)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.10/dist-packages (from torch) (11.8.87)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.10/dist-packages (from torch) (8.7.0.84)\n","Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.10/dist-packages (from torch) (11.11.3.6)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.0.86)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.1.48)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.5.86)\n","Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.10/dist-packages (from torch) (11.8.86)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.8)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /home/jovyan/.local/lib/python3.10/site-packages (from wandb) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.44)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.6)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (7.0.0)\n","Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.10.6)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from wandb) (2.22.0)\n","Requirement already satisfied: setproctitle in /home/jovyan/.local/lib/python3.10/site-packages (from wandb) (1.3.5)\n","Requirement already satisfied: setuptools in /home/jovyan/.local/lib/python3.10/site-packages (from wandb) (77.0.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: SimpleITK>=2.1 in /home/jovyan/.local/lib/python3.10/site-packages (from medpy) (2.4.1)\n","Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (3.3)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jovyan/.local/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtijmenl\u001b[0m (\u001b[33mtijmenl-universiteit-twente\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["!pip install nibabel monai matplotlib torch wandb scipy pandas numpy medpy\n","import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":null,"id":"f7a41a16-6597-41e4-9eb6-53f9d657f64f","metadata":{"tags":[],"id":"f7a41a16-6597-41e4-9eb6-53f9d657f64f","outputId":"0351c872-9885-4b42-9625-13ab2500c4cf"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/jovyan/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n","  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n","2025-03-31 20:26:00.305408: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2025-03-31 20:26:00.342816: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-31 20:26:00.342834: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-31 20:26:00.342855: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-31 20:26:00.350422: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-31 20:26:01.235489: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"name":"stdout","output_type":"stream","text":["Training Fold 1/5...\n"]},{"name":"stderr","output_type":"stream","text":["The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.19.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/jovyan/ACDC/wandb/run-20250331_202821-a89dqaww</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/tijmenl-universiteit-twente/ACDC%202D%20Unet%20Cross-Validation/runs/a89dqaww' target=\"_blank\">Fold_1</a></strong> to <a href='https://wandb.ai/tijmenl-universiteit-twente/ACDC%202D%20Unet%20Cross-Validation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/tijmenl-universiteit-twente/ACDC%202D%20Unet%20Cross-Validation' target=\"_blank\">https://wandb.ai/tijmenl-universiteit-twente/ACDC%202D%20Unet%20Cross-Validation</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/tijmenl-universiteit-twente/ACDC%202D%20Unet%20Cross-Validation/runs/a89dqaww' target=\"_blank\">https://wandb.ai/tijmenl-universiteit-twente/ACDC%202D%20Unet%20Cross-Validation/runs/a89dqaww</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 39%|███▉      | 78/200 [1:05:49<1:42:57, 50.63s/it]"]},{"name":"stdout","output_type":"stream","text":["Early stopping at epoch 79 due to no improvement in validation loss.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dice_score</td><td>▁▇▇▆▇██▇████████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇██</td></tr><tr><td>train_loss</td><td>█▆▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▃▃▃▂▁▂▁▁▃▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dice_score</td><td>0.90356</td></tr><tr><td>epoch</td><td>78</td></tr><tr><td>train_loss</td><td>1.09942</td></tr><tr><td>val_loss</td><td>0.18812</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">Fold_1</strong> at: <a href='https://wandb.ai/tijmenl-universiteit-twente/ACDC%202D%20Unet%20Cross-Validation/runs/a89dqaww' target=\"_blank\">https://wandb.ai/tijmenl-universiteit-twente/ACDC%202D%20Unet%20Cross-Validation/runs/a89dqaww</a><br> View project at: <a href='https://wandb.ai/tijmenl-universiteit-twente/ACDC%202D%20Unet%20Cross-Validation' target=\"_blank\">https://wandb.ai/tijmenl-universiteit-twente/ACDC%202D%20Unet%20Cross-Validation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20250331_202821-a89dqaww/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training Fold 2/5...\n"]},{"data":{"text/html":["Tracking run with wandb version 0.19.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/jovyan/ACDC/wandb/run-20250331_213415-j7x4tqcx</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/tijmenl-universiteit-twente/ACDC%202D%20Unet%20Cross-Validation/runs/j7x4tqcx' target=\"_blank\">Fold_2</a></strong> to <a href='https://wandb.ai/tijmenl-universiteit-twente/ACDC%202D%20Unet%20Cross-Validation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/tijmenl-universiteit-twente/ACDC%202D%20Unet%20Cross-Validation' target=\"_blank\">https://wandb.ai/tijmenl-universiteit-twente/ACDC%202D%20Unet%20Cross-Validation</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/tijmenl-universiteit-twente/ACDC%202D%20Unet%20Cross-Validation/runs/j7x4tqcx' target=\"_blank\">https://wandb.ai/tijmenl-universiteit-twente/ACDC%202D%20Unet%20Cross-Validation/runs/j7x4tqcx</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 30%|██▉       | 59/200 [45:50<1:49:44, 46.70s/it]"]}],"source":["#%% Adapted Script for Heart MRI Segmentation using a 2D UNet with Cross-Validation and Learning Rate Scheduling\n","import os\n","import glob\n","import nibabel as nib\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import monai\n","from monai.transforms import (\n","    Compose, EnsureChannelFirstd, ScaleIntensityd, Resized, RandZoomd, RandFlipd, RandRotated,\n","    Rand2DElasticd, RandAdjustContrastd, RandGaussianSmoothd, RandGaussianNoised, RandShiftIntensityd\n",")\n","from monai.metrics import DiceMetric\n","from monai.networks.nets import UNet\n","from monai.networks.utils import one_hot\n","from monai.losses import DiceCELoss\n","from sklearn.model_selection import KFold\n","from tqdm import tqdm\n","import wandb\n","\n","#%% Utility function for loading NIfTI images\n","def load_nii(img_path):\n","    nimg = nib.load(img_path)\n","    return nimg.get_fdata(), nimg.affine, nimg.header\n","\n","#%% Build dataset dictionary\n","def build_dict(data_path):\n","    image_dir = os.path.join(data_path, \"training\", \"image\")\n","    mask_dir = os.path.join(data_path, \"training\", \"segmentation\")\n","    image_paths = sorted(glob.glob(os.path.join(image_dir, \"*.nii.gz\")))\n","    mask_paths = sorted(glob.glob(os.path.join(mask_dir, \"*_gt.nii.gz\")))\n","    mask_dict = {os.path.basename(m).replace(\"_gt\", \"\"): m for m in mask_paths}\n","    dataset_dicts = []\n","    for img_path in image_paths:\n","        filename = os.path.basename(img_path)\n","        patient_number = filename.split('_')[0]\n","        mask_path = mask_dict.get(filename, None)\n","        if mask_path and os.path.exists(mask_path):\n","            dataset_dicts.append({\"patient\": patient_number, \"img\": img_path, \"mask\": mask_path})\n","    return dataset_dicts\n","\n","#%% Custom Transform to Load All Slices of Data\n","class LoadHeartData(monai.transforms.Transform):\n","    def __call__(self, sample):\n","        img_vol, _, _ = load_nii(sample['img'])\n","        mask_vol, _, _ = load_nii(sample['mask'])\n","        images = np.moveaxis(img_vol, -1, 0)\n","        masks = np.moveaxis(mask_vol, -1, 0)\n","        slice_list = []\n","        for i in range(images.shape[0]):\n","            slice_list.append({\n","                'img': images[i].astype(np.float32),\n","                'mask': masks[i].astype(np.uint8),\n","                'img_meta_dict': {'affine': np.eye(2)},\n","                'mask_meta_dict': {'affine': np.eye(2)}\n","            })\n","        return slice_list\n","\n","#%% Set data path\n","main_path = r'./database'\n","\n","#%% Build dataset dictionary\n","dataset_dicts = build_dict(main_path)\n","\n","#%% Define transforms\n","transforms = Compose([\n","    LoadHeartData(),\n","    EnsureChannelFirstd(keys=['img', 'mask'], channel_dim=\"no_channel\"),\n","    ScaleIntensityd(keys=['img']),\n","    Resized(keys=['img', 'mask'], spatial_size=(256, 256), mode=['bilinear', 'nearest']),\n","\n","    RandZoomd(keys=['img', 'mask'], min_zoom=0.90, max_zoom=1.10, mode=['bilinear', 'nearest'], prob=0.5),\n","    RandFlipd(keys=['img', 'mask'], prob=0.5, spatial_axis=1),\n","    RandRotated(keys=['img', 'mask'], range_x=0.1, range_y=0.1, mode=['bilinear', 'nearest'], prob=0.5),\n","    Rand2DElasticd(keys=['img', 'mask'], spacing=(5, 5), magnitude_range=(0, 0.1), prob=0.5, mode=['bilinear', 'nearest']),\n","    RandAdjustContrastd(keys=['img'], gamma=(0.7, 1.3), prob=0.3),\n","    RandGaussianSmoothd(keys=['img'], sigma_x=(0.5, 1.5), sigma_y=(0.5, 1.5), prob=0.3),\n","    RandGaussianNoised(keys=['img'], prob=0.3, mean=0.0, std=0.05),\n","    RandShiftIntensityd(keys=['img'], prob=0.5, offsets=(10,20))\n","])\n","\n","#%% Flatten dataset to handle all slices\n","def flatten_dataset(dataset_list, transform):\n","    flat_list = []\n","    for data in dataset_list:\n","        flat_list.extend(transform(data))\n","    return flat_list\n","\n","full_dataset = flatten_dataset(dataset_dicts * 3, transforms)\n","full_dataset = np.array(full_dataset)  # Convert to numpy for indexing in cross-validation\n","\n","#%% Cross-Validation Setup\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","num_epochs = 200\n","k_folds = 5\n","kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n","\n","fold_results = []\n","dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n","\n","#%% Cross-validation loop\n","for fold, (train_idx, val_idx) in enumerate(kf.split(full_dataset)):\n","    print(f\"Training Fold {fold + 1}/{k_folds}...\")\n","\n","    # Split dataset for this fold\n","    train_subset = full_dataset[train_idx].tolist()\n","    val_subset = full_dataset[val_idx].tolist()\n","\n","    train_dataset = monai.data.Dataset(data=train_subset)\n","    val_dataset = monai.data.Dataset(data=val_subset)\n","\n","    train_dataloader = DataLoader(train_dataset, batch_size=4, num_workers=2, pin_memory=True)\n","    val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n","\n","    class UNetWithDropout(monai.networks.nets.UNet):\n","        def __init__(self, spatial_dims, in_channels, out_channels, channels, strides, num_res_units, dropout_prob=0.5):\n","            super().__init__(\n","                spatial_dims=spatial_dims,\n","                in_channels=in_channels,\n","                out_channels=out_channels,\n","                channels=channels,\n","                strides=strides,\n","                num_res_units=num_res_units\n","            )\n","\n","            # Adding dropout after each block\n","            self.dropout = nn.Dropout(p=dropout_prob)\n","\n","        def forward(self, x):\n","            x = super().forward(x)\n","            x = self.dropout(x)\n","            return x\n","\n","    # Improved U-Net Model with increased capacity\n","    model = UNetWithDropout(\n","        spatial_dims=2,\n","        in_channels=1,\n","        out_channels=4,\n","        channels=(32, 64, 128, 256, 512),\n","        strides=(2, 2, 2, 2),\n","        num_res_units=2,\n","        dropout_prob=0.5\n","    ).to(device)\n","\n","    # Loss function & optimizer\n","    loss_function = DiceCELoss(to_onehot_y=True, softmax=True, include_background=True)\n","    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","    # Learning Rate Scheduler: reduce LR if validation loss plateaus\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n","\n","    # Initialize WandB for each fold\n","    run = wandb.init(\n","        project='ACDC 2D Unet Cross-Validation',\n","        name=f'Fold_{fold + 1}',\n","        config={'fold': fold + 1, 'batch_size': train_dataloader.batch_size}\n","    )\n","\n","    # Variables for early stopping and best model tracking\n","    patience = 20  # Number of epochs to wait for improvement before stopping\n","    epochs_without_improvement = 0  # Counter for epochs without improvement\n","    best_val_loss = float(\"inf\")\n","    best_dice_score = -float(\"inf\")\n","    best_epoch = 0\n","    best_model_wts = None\n","\n","    # Training loop for this fold\n","    for epoch in tqdm(range(num_epochs)):\n","        model.train()\n","        train_loss_epoch = 0.0\n","        for batch_data in train_dataloader:\n","            images = batch_data[\"img\"].to(device)\n","            masks = batch_data[\"mask\"].to(device)\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = loss_function(outputs, masks)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss_epoch += loss.item() * images.size(0)\n","        train_loss = train_loss_epoch / len(train_dataloader.dataset)\n","\n","        # Validation phase\n","        model.eval()\n","        val_loss_epoch = 0.0\n","        dice_metric.reset()\n","        with torch.no_grad():\n","            for batch_data in val_dataloader:\n","                images = batch_data[\"img\"].to(device)\n","                masks = batch_data[\"mask\"].to(device)\n","                outputs = model(images)\n","                loss = loss_function(outputs, masks)\n","                val_loss_epoch += loss.item() * images.size(0)\n","\n","                # Convert outputs to segmentation map and then one-hot encode\n","                outputs = torch.argmax(outputs, dim=1, keepdim=True)  # [B, 1, H, W]\n","                outputs_onehot = one_hot(outputs, num_classes=4)\n","                masks = masks.unsqueeze(1)  # Ensure shape is [B, 1, H, W]\n","                masks_onehot = one_hot(masks, num_classes=4)\n","                dice_metric(y_pred=outputs_onehot, y=masks_onehot)\n","\n","        val_loss = val_loss_epoch / len(val_dataloader.dataset)\n","        dice_score = dice_metric.aggregate().item()\n","\n","        wandb.log({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss, 'dice_score': dice_score})\n","\n","        # Step the scheduler with validation loss\n","        scheduler.step(val_loss)\n","\n","        # Early stopping: Check if validation loss improved\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            epochs_without_improvement = 0\n","            # Update best model checkpoint based on lowest validation loss\n","            best_epoch = epoch\n","            best_model_wts = model.state_dict()\n","        else:\n","            epochs_without_improvement += 1\n","            if epochs_without_improvement >= patience:\n","                print(f\"Early stopping at epoch {epoch + 1} due to no improvement in validation loss.\")\n","                break  # Stop training if no improvement in validation loss for `patience` epochs\n","\n","    # Save the best model for this fold\n","    torch.save(best_model_wts, f'bestHeartUNet_Fold{fold + 1}.pt')\n","    fold_results.append({\"val_loss\": best_val_loss, \"dice_score\": best_dice_score})\n","    run.finish()\n","\n","#%% Function to load ensemble models\n","def load_ensemble_models(model_paths, device):\n","    models = []\n","    for path in model_paths:\n","        model = UNet(\n","                spatial_dims=2,\n","                in_channels=1,\n","                out_channels=4,\n","                channels=(32, 64, 128, 256, 512),\n","                strides=(2, 2, 2, 2),\n","                num_res_units=2,\n","            ).to(device)\n","        model.load_state_dict(torch.load(path, map_location=device))\n","        model.eval()\n","        models.append(model)\n","        return models\n","\n","#%% Define the EnsembleModel globally to avoid pickle issues\n","class EnsembleModel(torch.nn.Module):\n","    def __init__(self, models):\n","        super(EnsembleModel, self).__init__()\n","        self.models = torch.nn.ModuleList(models)\n","\n","    def forward(self, x):\n","        # Collect and average the predictions (soft voting)\n","        outputs_list = [torch.softmax(model(x), dim=1) for model in self.models]\n","        avg_outputs = torch.mean(torch.stack(outputs_list), dim=0)\n","        return avg_outputs\n","\n","#%% Save the ensemble model\n","def save_ensemble_model(model_paths, device, save_path):\n","    ensemble_models = load_ensemble_models(model_paths, device)\n","    ensemble_model = EnsembleModel(ensemble_models)\n","\n","    # Save the entire model instead of just state_dict\n","    torch.save(ensemble_model, save_path)\n","    print(f\"Averaged Ensemble Model saved at: {save_path}\")\n","    return ensemble_model\n","\n","#%% Main Execution\n","model_paths = [os.path.join(f\"bestHeartUNet_Fold{i+1}.pt\") for i in range(5)]\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Save the entire ensemble model\n","ensemble_model_path = \"ensembleHeartUNet.pt\"\n","save_ensemble_model(model_paths, device, ensemble_model_path)"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}