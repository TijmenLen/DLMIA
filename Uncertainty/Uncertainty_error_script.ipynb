{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dJatkZ4n-1sG",
   "metadata": {
    "id": "dJatkZ4n-1sG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%% Set data path\n",
    "data_path = r'./database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b927e7-7482-49b7-ac08-874c4501f275",
   "metadata": {
    "id": "e2b927e7-7482-49b7-ac08-874c4501f275",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing all needed packages\n",
    "import os\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import monai\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.transforms import Compose, ScaleIntensityd, EnsureChannelFirstd, RandZoomd, RandFlipd, RandRotated, Resized, RandAdjustContrastd, RandGaussianSmoothd, RandGaussianNoised, Rand2DElasticd, RandShiftIntensityd\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.utils import one_hot\n",
    "from monai.networks.nets import UNet\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import cv2\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6238fa9-9ef3-45fa-8205-1d1ca6179a91",
   "metadata": {
    "id": "b6238fa9-9ef3-45fa-8205-1d1ca6179a91",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%% Adapted Script for Heart MRI Segmentation using a 2D UNet with Cross-Validation and Learning Rate Scheduling\n",
    "\n",
    "#%% Utility function for loading NIfTI images\n",
    "def load_nii(img_path):\n",
    "    nimg = nib.load(img_path)\n",
    "    return nimg.get_fdata(), nimg.affine, nimg.header\n",
    "\n",
    "##%% Build a dictionary for the test dataset\n",
    "def build_test_dict(data_path):\n",
    "    image_dir = os.path.join(data_path, \"testing\", \"image\")\n",
    "    mask_dir = os.path.join(data_path, \"testing\", \"segmentation\")\n",
    "\n",
    "    image_paths = sorted(glob.glob(os.path.join(image_dir, \"*.nii.gz\")))\n",
    "    mask_paths = sorted(glob.glob(os.path.join(mask_dir, \"*_gt.nii.gz\")))\n",
    "\n",
    "    mask_dict = {os.path.basename(m).replace(\"_gt\", \"\"): m for m in mask_paths}\n",
    "    dataset_dicts = []\n",
    "    for img_path in image_paths:\n",
    "        filename = os.path.basename(img_path)\n",
    "        patient_number = filename.split('_')[0]\n",
    "        frame = os.path.splitext(os.path.splitext(filename)[0])[0].split('_')[1]\n",
    "        mask_path = mask_dict.get(filename, None)\n",
    "        if mask_path and os.path.exists(mask_path):\n",
    "            dataset_dicts.append({\"patient\": patient_number, \"img\": img_path, \"mask\": mask_path, \"img_meta_dict\": {\"filename\": filename, \"patient_id\": patient_number, \"frame\": frame}})\n",
    "    return dataset_dicts\n",
    "\n",
    "class LoadHeartData(monai.transforms.Transform):\n",
    "    def __call__(self, sample):\n",
    "        img_vol, _, _ = load_nii(sample['img'])\n",
    "        mask_vol, _, _ = load_nii(sample['mask'])\n",
    "        images = np.moveaxis(img_vol, -1, 0)\n",
    "        masks = np.moveaxis(mask_vol, -1, 0)\n",
    "        patient_id = sample['img_meta_dict'].get('patient_id', 'unknown')\n",
    "        filename = sample['img_meta_dict'].get('filename', 'unknown')\n",
    "        frame = sample['img_meta_dict'].get('frame', 'unknown') \n",
    "        slice_list = []\n",
    "        for i in range(images.shape[0]):\n",
    "            slice_list.append({\n",
    "                'img': images[i].astype(np.float32),\n",
    "                'mask': masks[i].astype(np.uint8),\n",
    "                'img_meta_dict': {\n",
    "                    'affine': np.eye(2),\n",
    "                    'patient_id': patient_id,\n",
    "                    'filename': filename,\n",
    "                    'slice_index': i,\n",
    "                    'frame': frame\n",
    "                },\n",
    "                'mask_meta_dict': {'affine': np.eye(2)}\n",
    "            })\n",
    "        return slice_list\n",
    "\n",
    "#%% Set data path\n",
    "main_path = r'./database'\n",
    "#main_path = r\"/content/drive/MyDrive/ACDC/database\"\n",
    "\n",
    "#%% Build dataset dictionary (training + validation combined for CV)\n",
    "dataset_dicts = build_test_dict(main_path)\n",
    "\n",
    "#%% Define transforms\n",
    "transforms = Compose([\n",
    "    LoadHeartData(),\n",
    "    EnsureChannelFirstd(keys=['img', 'mask'], channel_dim=\"no_channel\"),\n",
    "    ScaleIntensityd(keys=['img'], minv=0, maxv=1),\n",
    "    Resized(keys=['img', 'mask'], spatial_size=(256, 256), mode=['bilinear', 'nearest']),\n",
    "    RandZoomd(keys=['img', 'mask'], min_zoom=0.9, max_zoom=1.1, mode=['bilinear', 'nearest'], prob=0.5),\n",
    "    RandFlipd(keys=['img', 'mask'], prob=0.5, spatial_axis=1),\n",
    "    RandRotated(keys=['img', 'mask'], range_x=0.1, range_y=0.1, mode=['bilinear', 'nearest'], prob=0.5),\n",
    "    Rand2DElasticd(keys=['img', 'mask'], spacing=(5, 5), magnitude_range=(0, 0.1), prob=0.5, mode=['bilinear', 'nearest']),\n",
    "    RandAdjustContrastd(keys=['img'], gamma=(0.8, 1.2), prob=0.3),\n",
    "    RandGaussianSmoothd(keys=['img'], sigma_x=(0.5, 1.5), sigma_y=(0.5, 1.5), prob=0.3),\n",
    "    RandGaussianNoised(keys=['img'], prob=0.3, mean=0.0, std=0.05),\n",
    "    RandShiftIntensityd(keys=['img'], prob=0.5, offsets=(10,20))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1J84G0HELjA-",
   "metadata": {
    "id": "1J84G0HELjA-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%% Flatten dataset to handle all slices\n",
    "def flatten_dataset(dataset_list, transform):\n",
    "    flat_list = []\n",
    "    for data in dataset_list:\n",
    "        flat_list.extend(transform(data))\n",
    "    return flat_list\n",
    "\n",
    "#full_dataset = flatten_dataset(dataset_dicts * 3, transforms)\n",
    "#full_dataset = np.array(full_dataset)  # Convert to numpy for indexing in cross-validation\n",
    "\n",
    "#%% Cross-Validation Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 200\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f43bee-7727-4c04-a632-519a93860d88",
   "metadata": {
    "id": "e7f43bee-7727-4c04-a632-519a93860d88",
    "outputId": "360f9ec2-f719-46ba-9a81-11af230cceed",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir = \".\" \n",
    "\n",
    "#%% Build and flatten the test dataset\n",
    "test_dicts = build_test_dict(r'./database')\n",
    "test_flat = flatten_dataset(test_dicts, transforms)\n",
    "#%% Create test DataLoader\n",
    "test_dataset = monai.data.Dataset(data=test_flat)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "#%% Function to load ensemble models\n",
    "def load_ensemble_models(model_paths, device):\n",
    "    models = []\n",
    "    for path in model_paths:\n",
    "        model = UNet(\n",
    "            spatial_dims=2,\n",
    "            in_channels=1,\n",
    "            out_channels=4,\n",
    "            channels=(32, 64, 128, 256, 512),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,\n",
    "        ).to(device)\n",
    "        model.load_state_dict(torch.load(path, map_location=device))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "#FOR UNCERTAINTY #https://medium.com/biased-algorithms/uncertainty-estimation-in-machine-learning-with-monte-carlo-dropout-72377f5ee276\n",
    "\n",
    "ensemble_model_path = \"ensembleHeartUNet.pt\"\n",
    "\n",
    "model_paths = [os.path.join(model_dir, f\"bestHeartUNet_Fold{i+1}.pt\") for i in range(5)]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# EnsembleModel with MC Dropout for uncertainty calculation\n",
    "class EnsembleModelWithUncertainty(torch.nn.Module):\n",
    "    def __init__(self, models, num_samples_mc=10):\n",
    "        super(EnsembleModelWithUncertainty, self).__init__()\n",
    "        self.models = torch.nn.ModuleList(models)\n",
    "        self.num_samples_mc = num_samples_mc  # Number of Monte Carlo samples\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs_list = []\n",
    "        for model in self.models:\n",
    "            model.train()  # Dropout is actief\n",
    "            model_outputs = []\n",
    "            for _ in range(self.num_samples_mc):\n",
    "                model_outputs.append(torch.softmax(model(x), dim=1))  # Voorspellingen met actieve dropout\n",
    "            outputs_list.append(torch.stack(model_outputs, dim=0))  # [num_samples_mc, B, C, H, W]\n",
    "\n",
    "        # Combineer alle voorspellingen van het ensemble\n",
    "        all_outputs = torch.cat(outputs_list, dim=0)  # [num_samples_mc * len(models), B, C, H, W]\n",
    "\n",
    "        # Bereken het gemiddelde en de standaarddeviatie\n",
    "        mean_output = torch.mean(all_outputs, dim=0)  # Gemiddelde voorspelling (mean_pred)\n",
    "        std_output = torch.std(all_outputs, dim=0)    # Standaarddeviatie (uncertainty)\n",
    "\n",
    "        return mean_output, std_output  # Retourneer zowel het gemiddelde als de standaarddeviatie\n",
    "\n",
    "# Evaluation phase:\n",
    "def compute_ensemble_dice_and_uncertainty(model_paths, device, test_dataloader, num_samples_mc=10):\n",
    "    # Load ensemble models\n",
    "    ensemble_models = load_ensemble_models(model_paths, device)\n",
    "    ensemble_model = EnsembleModelWithUncertainty(ensemble_models, num_samples_mc)\n",
    "    \n",
    "    # Initialize Dice metric and empty list for uncertainty maps\n",
    "    dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "    dice_metric.reset()\n",
    "    uncertainty_maps = []\n",
    "    total_uncertainty = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            images = batch[\"img\"].to(device)\n",
    "            # Perform inference with the ensemble model and get predictions\n",
    "            mean_pred, std_pred = ensemble_model(images)\n",
    "            # Calculate Dice score for the current batch\n",
    "            preds = torch.argmax(mean_pred, dim=1, keepdim=True)  # Select the class with the highest probability\n",
    "            preds_onehot = one_hot(preds, num_classes=4)\n",
    "            masks = batch[\"mask\"].to(device).unsqueeze(1)\n",
    "            masks_onehot = one_hot(masks, num_classes=4)\n",
    "            dice_metric(y_pred=preds_onehot, y=masks_onehot)\n",
    "\n",
    "            # Calculate and store uncertainty (e.g., standard deviation)\n",
    "            batch_uncertainty = std_pred.mean().item()  # Gemiddelde onzekerheid per batch\n",
    "            total_uncertainty += batch_uncertainty\n",
    "            num_batches += 1\n",
    "            uncertainty_maps.append(std_pred.cpu().numpy())  # Add uncertainty map\n",
    "            \n",
    "    # Aggregate the Dice score for the whole dataset\n",
    "    dice_score = dice_metric.aggregate().item()\n",
    "    dice_metric.reset()\n",
    "    \n",
    "    # Compute overall uncertainty score\n",
    "    avg_uncertainty = total_uncertainty / num_batches if num_batches > 0 else 0.0\n",
    "    # Return the Dice score, the list of uncertainty maps, and overall uncertainty score\n",
    "    return dice_score, uncertainty_maps, avg_uncertainty\n",
    "\n",
    "dice_score, uncertainty_maps, avg_uncertainty = compute_ensemble_dice_and_uncertainty(model_paths, device, test_dataloader)\n",
    "\n",
    "#print scores\n",
    "print(f\"Ensemble Dice Score on Test Dataset: {dice_score}\")\n",
    "print(f\"Overall Uncertainty Score: {avg_uncertainty}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548315a3-0b59-49e7-895b-6acce53fe0ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#NEW CLASS ENSEMBLEMODEL TO OUTPUT UNCERTAINTY\n",
    "class EnsembleModel(torch.nn.Module):\n",
    "    def __init__(self, models, num_samples_mc=10):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.models = torch.nn.ModuleList(models)\n",
    "        self.num_samples_mc = num_samples_mc  #number of monte carlo samples\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs_list = []\n",
    "        for model in self.models:\n",
    "            model.train()  # put it in train mode to ensure dropout remains active\n",
    "            model_outputs = []\n",
    "            for _ in range(self.num_samples_mc):\n",
    "                model_outputs.append(torch.softmax(model(x), dim=1))  \n",
    "            outputs_list.append(torch.stack(model_outputs, dim=0))  # [num_samples_mc, B, C, H, W]\n",
    "\n",
    "        # combine the results of the ensemble\n",
    "        all_outputs = torch.cat(outputs_list, dim=0)  # [num_samples_mc * len(models), B, C, H, W]\n",
    "\n",
    "        # calculate mean and standard deviation\n",
    "        mean_output = torch.mean(all_outputs, dim=0)  # mean prediction\n",
    "        std_output = torch.std(all_outputs, dim=0)   # uncertainty (standard deviation)\n",
    "\n",
    "        return mean_output, std_output  #return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb79cec-79a2-4a22-9579-3d5984513f46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#only patient 149\n",
    "from collections import defaultdict\n",
    "\n",
    "# Create directory for saving plots\n",
    "output_dir = \"Report_uncertainty_error\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# GROUP samples per patient frame\n",
    "grouped_samples = defaultdict(list)\n",
    "\n",
    "# get samples per patient and frame\n",
    "for idx in range(len(test_dataset)):\n",
    "    sample = test_dataset[idx]\n",
    "    pid = sample[\"img_meta_dict\"][\"patient_id\"]\n",
    "    frame = sample[\"img_meta_dict\"].get(\"frame\", \"N/A\")\n",
    "    key = (pid, frame)\n",
    "    grouped_samples[key].append(sample)\n",
    "\n",
    "#print(\"Alle patient-frame combinaties in grouped_samples:\")\n",
    "#for (patient_id, frame) in grouped_samples.keys():\n",
    " #   print(f\"Patient: {patient_id}, Frame: {frame}\")\n",
    "\n",
    "    \n",
    "with torch.no_grad():\n",
    "    for (patient_id, frame), samples in grouped_samples.items():\n",
    "        if not (str(patient_id) == \"patient149\" and str(frame) == \"frame12\"):\n",
    "            continue\n",
    "\n",
    "        fig, axes = plt.subplots(len(samples), 5, figsize=(24, 3 * len(samples)))\n",
    "        fig.subplots_adjust(top=0.92, wspace=0.01, hspace=0.4)\n",
    "        #fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        fig.suptitle(f\"Patient: {patient_id}, Frame: {frame}\", fontsize=16, fontweight='bold')\n",
    "\n",
    "        if len(samples) == 1:\n",
    "            axes = [axes]  # Ensure it's iterable\n",
    "\n",
    "        for row, sample in enumerate(samples):\n",
    "            slice_index = sample[\"img_meta_dict\"].get(\"slice_index\", 0)\n",
    "            img = sample[\"img\"].to(device).unsqueeze(0)\n",
    "            mask = sample[\"mask\"].to(device).unsqueeze(0)\n",
    "\n",
    "            ensemble_models = load_ensemble_models(model_paths, device)\n",
    "            ensemble_model = EnsembleModel(ensemble_models, num_samples_mc=10)\n",
    "\n",
    "            mean_pred, uncertainty = ensemble_model(img)\n",
    "            output_prob = torch.softmax(mean_pred, dim=1)\n",
    "            pred = torch.argmax(output_prob, dim=1, keepdim=True)\n",
    "\n",
    "            img_np = img.squeeze().cpu().numpy()\n",
    "            mask_np = mask.squeeze().cpu().numpy()\n",
    "            pred_np = pred.squeeze().cpu().numpy()\n",
    "            uncertainty_np = uncertainty.squeeze().cpu().numpy().mean(axis=0)\n",
    "\n",
    "            mask_rv = (mask_np == 1).astype(np.uint8)\n",
    "            mask_myo = (mask_np == 2).astype(np.uint8)\n",
    "            mask_lv = (mask_np == 3).astype(np.uint8)\n",
    "            pred_rv = (pred_np == 1).astype(np.uint8)\n",
    "            pred_myo = (pred_np == 2).astype(np.uint8)\n",
    "            pred_lv = (pred_np == 3).astype(np.uint8)\n",
    "\n",
    "            error_lv = np.abs(pred_lv - mask_lv)\n",
    "            error_rv = np.abs(pred_rv - mask_rv)\n",
    "            error_myo = np.abs(pred_myo - mask_myo)\n",
    "            error_background = ((mask_np == 0) & (pred_np != 0)).astype(np.uint8)\n",
    "            combined_error = (pred_np != mask_np).astype(np.uint8)\n",
    "\n",
    "            row_axes = axes[row]\n",
    "\n",
    "            row_axes[0].imshow(img_np, cmap=\"gray\")\n",
    "            row_axes[0].set_title(f\"Slice {slice_index}\")\n",
    "\n",
    "            row_axes[1].imshow(mask_np, cmap=\"gray\")\n",
    "            row_axes[1].set_title(\"GT Mask\")\n",
    "\n",
    "            row_axes[2].imshow(pred_np, cmap=\"gray\")\n",
    "            row_axes[2].set_title(\"Prediction\")\n",
    "\n",
    "            row_axes[3].imshow(uncertainty_np, cmap=\"hot\")\n",
    "            row_axes[3].set_title(\"Uncertainty\")\n",
    "\n",
    "            row_axes[4].imshow(combined_error, cmap=\"hot\")\n",
    "            row_axes[4].set_title(\"Total Error\")\n",
    "\n",
    "            images = [img_np, mask_np, pred_np, uncertainty_np, combined_error]\n",
    "            titles = [\"Slice\", \"GT Mask\", \"Prediction\", \"Uncertainty\", \"Total Error\"]\n",
    "\n",
    "            for col, (ax, img, title) in enumerate(zip(axes[row], images, titles)):\n",
    "                ax.imshow(img, cmap=\"hot\" if title in [\"Uncertainty\", \"Total Error\"] else \"gray\")\n",
    "                ax.set_title(f\"{title} {slice_index}\" if title == \"Slice\" else title)\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "        save_path = os.path.join(output_dir, f\"Patient_{patient_id}_Frame_{frame}_ALL_SLICES.png\")\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b06036e-6ee9-4537-a69c-0143eec16ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kan weg als andere het doen VISUALIZATION\n",
    "# Create directory for saving plots\n",
    "output_dir = \"Plots_uncertainty_error\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Resize image because we do not want to apply transforms on the visualized image\n",
    "# (leads to weird intensities), but we do want it to be the same size\n",
    "def resize_image(img, size=(256, 256)):\n",
    "    # If img is a tensor, convert it to a NumPy array\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        img = img.cpu().numpy()\n",
    "    img_resized = cv2.resize(img, size, interpolation=cv2.INTER_LINEAR)\n",
    "    return img_resized\n",
    "\n",
    "indices = list(range(len(test_dataset)))\n",
    "#print(f\"Selected test sample indices: {indices}\")\n",
    "\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "\n",
    "# Inference and debugging with uncertainty maps\n",
    "with torch.no_grad():\n",
    "    for i, idx in enumerate(indices):\n",
    "        # Visualize the results\n",
    "        sample = test_dataset[idx]\n",
    "        \n",
    "        # Load original NIfTI slice to ensure accurate visualization\n",
    "        patient_id = sample[\"img_meta_dict\"][\"patient_id\"]\n",
    "        frame = sample[\"img_meta_dict\"].get(\"frame\", \"N/A\")\n",
    "        slice_index = sample[\"img_meta_dict\"].get(\"slice_index\", 0)\n",
    "        matching_sample = next((s for s in test_dicts if s[\"patient\"] == patient_id and s[\"img_meta_dict\"][\"frame\"] == frame), None)\n",
    "\n",
    "        if matching_sample is not None:\n",
    "            nifti_img = nib.load(matching_sample[\"img\"])\n",
    "            volume_data = nifti_img.get_fdata()\n",
    "            if volume_data.ndim == 3 and slice_index < volume_data.shape[-1]:\n",
    "                raw_slice = volume_data[..., slice_index]\n",
    "                img_data_resized = resize_image(raw_slice)\n",
    "            else:\n",
    "                img_data_resized = np.zeros((256, 256))  # fallback if invalid\n",
    "        else:\n",
    "            img_data_resized = np.zeros((256, 256))  # fallback if not found\n",
    "\n",
    "        # Get the filename\n",
    "        filename = sample.get(\"filename\", sample.get(\"image_path\", f\"Slice {idx}\"))\n",
    "        patient_id = sample[\"img_meta_dict\"][\"patient_id\"]\n",
    "        frame = sample[\"img_meta_dict\"].get(\"frame\", \"N/A\")\n",
    "        slice_index = sample[\"img_meta_dict\"].get(\"slice_index\", \"N/A\")\n",
    "        print(f\"Patient: {patient_id}, Frame: {frame}, Slice: {slice_index}\")\n",
    "        \n",
    "        img = sample[\"img\"].to(device).unsqueeze(0)  # Add batch dimension\n",
    "        mask = sample[\"mask\"].to(device).unsqueeze(0)  # Keep 1-channel mask\n",
    "\n",
    "        # Load the model\n",
    "        ensemble_models = load_ensemble_models(model_paths, device)\n",
    "        ensemble_model = EnsembleModel(ensemble_models, num_samples_mc=10)\n",
    "\n",
    "        # Apply model on one image\n",
    "        mean_pred, uncertainty = ensemble_model(img)\n",
    "\n",
    "        # Apply softmax to the mean prediction for class probabilities\n",
    "        output_prob = torch.softmax(mean_pred, dim=1)\n",
    "\n",
    "        # Apply argmax to get the predicted class\n",
    "        pred = torch.argmax(output_prob, dim=1, keepdim=True)\n",
    "\n",
    "        # Convert tensors to NumPy arrays for plotting\n",
    "        img_np = img.squeeze().cpu().numpy()\n",
    "        \n",
    "        mask_np = mask.squeeze().cpu().numpy()\n",
    "        mask_rv = (mask_np == 1).astype(np.uint8)\n",
    "        mask_myo = (mask_np == 2).astype(np.uint8)\n",
    "        mask_lv = (mask_np == 3).astype(np.uint8)\n",
    "        \n",
    "        pred_np = pred.squeeze().cpu().numpy()\n",
    "        pred_rv = (pred_np == 1).astype(np.uint8)\n",
    "        pred_myo = (pred_np == 2).astype(np.uint8)\n",
    "        pred_lv = (pred_np == 3).astype(np.uint8)\n",
    "    \n",
    "        # Error maps: where prediction and ground truth differ\n",
    "        error_lv = np.abs(pred_lv - mask_lv)\n",
    "        error_rv = np.abs(pred_rv - mask_rv)\n",
    "        error_myo = np.abs(pred_myo - mask_myo)\n",
    "        \n",
    "        # Pixels that are background in the ground truth but predicted as something else\n",
    "        error_background = ((mask_np == 0) & (pred_np != 0)).astype(np.uint8)\n",
    "        combined_error = (pred_np != mask_np).astype(np.uint8)\n",
    "\n",
    "        uncertainty_np = uncertainty.squeeze().cpu().numpy()  # Uncertainty map (standard deviation)\n",
    "        uncertainty_np = uncertainty_np.mean(axis=0)  # Make 2D map\n",
    "\n",
    "        # Compute Dice score\n",
    "        mask_onehot = one_hot(mask, num_classes=4)\n",
    "        pred_onehot = one_hot(pred, num_classes=4)\n",
    "        dice_metric(y_pred=pred_onehot, y=mask_onehot)\n",
    "        dice_score = dice_metric.aggregate().item()\n",
    "        dice_metric.reset()\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 9, figsize=(22,4))\n",
    "        fig.suptitle(f\"Patient: {patient_id}, Frame: {frame}, Slice: {slice_index}\", fontsize=14, fontweight='bold')\n",
    "\n",
    "        axes[0].imshow(img_np, cmap=\"gray\")\n",
    "        axes[0].set_title(f\"\\n{filename}\")\n",
    "\n",
    "        axes[1].imshow(mask_np, cmap=\"gray\")\n",
    "        axes[1].set_title(\"Ground Truth Mask\")\n",
    "\n",
    "        axes[2].imshow(pred_np, cmap=\"gray\")\n",
    "        axes[2].set_title(\"Total Segmentation\")\n",
    "\n",
    "        axes[3].imshow(uncertainty_np, cmap=\"hot\")\n",
    "        axes[3].set_title(\"Uncertainty\")\n",
    "    \n",
    "        axes[4].imshow(error_lv, cmap=\"hot\")\n",
    "        axes[4].set_title(\"LV Error\")\n",
    "\n",
    "        axes[5].imshow(error_rv, cmap=\"hot\")\n",
    "        axes[5].set_title(\"RV Error\")\n",
    "\n",
    "        axes[6].imshow(error_myo, cmap=\"hot\")\n",
    "        axes[6].set_title(\"MYO Error\")\n",
    "        \n",
    "        axes[7].imshow(error_background, cmap=\"hot\")\n",
    "        axes[7].set_title(\"Background Errors\")\n",
    "\n",
    "        axes[8].imshow(combined_error, cmap=\"hot\")\n",
    "        axes[8].set_title(\"Combined Error Map\")\n",
    "        \n",
    "        # Hide axes for all subplots\n",
    "        for ax in axes:\n",
    "            ax.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "                # Save plot\n",
    "        #save_path = os.path.join(output_dir, f\"Patient_{patient_id}_Frame_{frame}_Slice_{slice_index}.png\")\n",
    "        #plt.savefig(save_path, bbox_inches='tight')  #\n",
    "        plt.show()  \n",
    "        plt.close()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5d75be-1500-4cff-9815-bfc3f9a8afa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#WITH ALL ERROR PLOTS \n",
    "from collections import defaultdict\n",
    "\n",
    "# Create directory for saving plots\n",
    "output_dir = \"Patients_uncertainty_error\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Group samples per patient frame\n",
    "grouped_samples = defaultdict(list)\n",
    "\n",
    "# get samplees per patient & frame\n",
    "for idx in range(len(test_dataset)):\n",
    "    sample = test_dataset[idx]\n",
    "    pid = sample[\"img_meta_dict\"][\"patient_id\"]\n",
    "    frame = sample[\"img_meta_dict\"].get(\"frame\", \"N/A\")\n",
    "    key = (pid, frame)\n",
    "    grouped_samples[key].append(sample)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (patient_id, frame), samples in grouped_samples.items():\n",
    "        fig, axes = plt.subplots(len(samples), 9, figsize=(24, 3 * len(samples)))\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.95]) \n",
    "        fig.suptitle(f\"Patient: {patient_id}, Frame: {frame}\", fontsize=16, fontweight='bold')\n",
    "\n",
    "        if len(samples) == 1:\n",
    "            axes = [axes]  # Ensure it's iterable in single-slice case\n",
    "\n",
    "        for row, sample in enumerate(samples):\n",
    "            slice_index = sample[\"img_meta_dict\"].get(\"slice_index\", 0)\n",
    "            img = sample[\"img\"].to(device).unsqueeze(0)\n",
    "            mask = sample[\"mask\"].to(device).unsqueeze(0)\n",
    "\n",
    "            ensemble_models = load_ensemble_models(model_paths, device)\n",
    "            ensemble_model = EnsembleModel(ensemble_models, num_samples_mc=10)\n",
    "\n",
    "            mean_pred, uncertainty = ensemble_model(img)\n",
    "            output_prob = torch.softmax(mean_pred, dim=1)\n",
    "            pred = torch.argmax(output_prob, dim=1, keepdim=True)\n",
    "\n",
    "            img_np = img.squeeze().cpu().numpy()\n",
    "            mask_np = mask.squeeze().cpu().numpy()\n",
    "            pred_np = pred.squeeze().cpu().numpy()\n",
    "            uncertainty_np = uncertainty.squeeze().cpu().numpy().mean(axis=0)\n",
    "\n",
    "            mask_rv = (mask_np == 1).astype(np.uint8)\n",
    "            mask_myo = (mask_np == 2).astype(np.uint8)\n",
    "            mask_lv = (mask_np == 3).astype(np.uint8)\n",
    "            pred_rv = (pred_np == 1).astype(np.uint8)\n",
    "            pred_myo = (pred_np == 2).astype(np.uint8)\n",
    "            pred_lv = (pred_np == 3).astype(np.uint8)\n",
    "\n",
    "            error_lv = np.abs(pred_lv - mask_lv)\n",
    "            error_rv = np.abs(pred_rv - mask_rv)\n",
    "            error_myo = np.abs(pred_myo - mask_myo)\n",
    "            error_background = ((mask_np == 0) & (pred_np != 0)).astype(np.uint8)\n",
    "            combined_error = (pred_np != mask_np).astype(np.uint8)\n",
    "\n",
    "            row_axes = axes[row]\n",
    "\n",
    "            row_axes[0].imshow(img_np, cmap=\"gray\")\n",
    "            row_axes[0].set_title(f\"Slice {slice_index}\")\n",
    "\n",
    "            row_axes[1].imshow(mask_np, cmap=\"gray\")\n",
    "            row_axes[1].set_title(\"GT Mask\")\n",
    "\n",
    "            row_axes[2].imshow(pred_np, cmap=\"gray\")\n",
    "            row_axes[2].set_title(\"Prediction\")\n",
    "\n",
    "            row_axes[3].imshow(uncertainty_np, cmap=\"hot\")\n",
    "            row_axes[3].set_title(\"Uncertainty\")\n",
    "\n",
    "            row_axes[4].imshow(error_lv, cmap=\"hot\")\n",
    "            row_axes[4].set_title(\"LV Error\")\n",
    "\n",
    "            row_axes[5].imshow(error_rv, cmap=\"hot\")\n",
    "            row_axes[5].set_title(\"RV Error\")\n",
    "\n",
    "            row_axes[6].imshow(error_myo, cmap=\"hot\")\n",
    "            row_axes[6].set_title(\"MYO Error\")\n",
    "\n",
    "            row_axes[7].imshow(error_background, cmap=\"hot\")\n",
    "            row_axes[7].set_title(\"Background Error\")\n",
    "\n",
    "            row_axes[8].imshow(combined_error, cmap=\"hot\")\n",
    "            row_axes[8].set_title(\"Combined Error\")\n",
    "\n",
    "            for ax in row_axes:\n",
    "                ax.axis(\"off\")\n",
    "    \n",
    "        save_path = os.path.join(output_dir, f\"Patient_{patient_id}_Frame_{frame}_ALL_SLICES.png\")\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8d449-1a23-41c1-b23e-1202a6f349ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create directory for saving plots\n",
    "output_dir = \"Report_uncertainty_error\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# GROUP samples per patient frame\n",
    "grouped_samples = defaultdict(list)\n",
    "\n",
    "# Get samples per patient and frame\n",
    "for idx in range(len(test_dataset)):\n",
    "    sample = test_dataset[idx]\n",
    "    pid = sample[\"img_meta_dict\"][\"patient_id\"]\n",
    "    frame = sample[\"img_meta_dict\"].get(\"frame\", \"N/A\")\n",
    "    key = (pid, frame)\n",
    "    grouped_samples[key].append(sample)\n",
    "\n",
    "#print(\"Alle patient-frame combinaties in grouped_samples:\")\n",
    "#for (patient_id, frame) in grouped_samples.keys():\n",
    " #   print(f\"Patient: {patient_id}, Frame: {frame}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (patient_id, frame), samples in grouped_samples.items():\n",
    "        if not (str(patient_id) == \"patient149\" and str(frame) == \"frame12\"):\n",
    "            continue\n",
    "\n",
    "        # Set a smaller figure size and reduce spacing\n",
    "        fig, axes = plt.subplots(len(samples), 5, figsize=(20, 3 * len(samples)))\n",
    "        plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "        # Tighten layout further: reduce both hspace and wspace\n",
    "        #fig.subplots_adjust(hspace=2, wspace=0.05)  # Decrease space between rows and columns\n",
    "\n",
    "        fig.suptitle(f\"Patient: {patient_id}, Frame: {frame}\", fontsize=16, fontweight='bold')\n",
    "\n",
    "        if len(samples) == 1:\n",
    "            axes = [axes]  # Ensure it's iterable\n",
    "\n",
    "        for row, sample in enumerate(samples):\n",
    "            slice_index = sample[\"img_meta_dict\"].get(\"slice_index\", 0)\n",
    "            img = sample[\"img\"].to(device).unsqueeze(0)\n",
    "            mask = sample[\"mask\"].to(device).unsqueeze(0)\n",
    "\n",
    "            ensemble_models = load_ensemble_models(model_paths, device)\n",
    "            ensemble_model = EnsembleModel(ensemble_models, num_samples_mc=10)\n",
    "\n",
    "            mean_pred, uncertainty = ensemble_model(img)\n",
    "            output_prob = torch.softmax(mean_pred, dim=1)\n",
    "            pred = torch.argmax(output_prob, dim=1, keepdim=True)\n",
    "\n",
    "            img_np = img.squeeze().cpu().numpy()\n",
    "            mask_np = mask.squeeze().cpu().numpy()\n",
    "            pred_np = pred.squeeze().cpu().numpy()\n",
    "            uncertainty_np = uncertainty.squeeze().cpu().numpy().mean(axis=0)\n",
    "\n",
    "            mask_rv = (mask_np == 1).astype(np.uint8)\n",
    "            mask_myo = (mask_np == 2).astype(np.uint8)\n",
    "            mask_lv = (mask_np == 3).astype(np.uint8)\n",
    "            pred_rv = (pred_np == 1).astype(np.uint8)\n",
    "            pred_myo = (pred_np == 2).astype(np.uint8)\n",
    "            pred_lv = (pred_np == 3).astype(np.uint8)\n",
    "\n",
    "            error_lv = np.abs(pred_lv - mask_lv)\n",
    "            error_rv = np.abs(pred_rv - mask_rv)\n",
    "            error_myo = np.abs(pred_myo - mask_myo)\n",
    "            error_background = ((mask_np == 0) & (pred_np != 0)).astype(np.uint8)\n",
    "            combined_error = (pred_np != mask_np).astype(np.uint8)\n",
    "\n",
    "            row_axes = axes[row]\n",
    "\n",
    "            row_axes[0].imshow(img_np, cmap=\"gray\")\n",
    "            row_axes[0].set_title(f\"Slice {slice_index}\")\n",
    "\n",
    "            row_axes[1].imshow(mask_np, cmap=\"gray\")\n",
    "            row_axes[1].set_title(\"GT Mask\")\n",
    "\n",
    "            row_axes[2].imshow(pred_np, cmap=\"gray\")\n",
    "            row_axes[2].set_title(\"Prediction\")\n",
    "\n",
    "            row_axes[3].imshow(uncertainty_np, cmap=\"hot\")\n",
    "            row_axes[3].set_title(\"Uncertainty\")\n",
    "\n",
    "            row_axes[4].imshow(combined_error, cmap=\"hot\")\n",
    "            row_axes[4].set_title(\"Total Error\")\n",
    "\n",
    "            for ax in row_axes:\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "        save_path = os.path.join(output_dir, f\"Patient_{patient_id}_Frame_{frame}_ALL_SLICES.png\")\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727091a5-5ac8-400a-b4c3-28e245780d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create directory for saving plots\n",
    "output_dir = \"Report_uncertainty_error\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# GROUP samples per patient frame\n",
    "grouped_samples = defaultdict(list)\n",
    "\n",
    "# Get samples per patient and frame\n",
    "for idx in range(len(test_dataset)):\n",
    "    sample = test_dataset[idx]\n",
    "    pid = sample[\"img_meta_dict\"][\"patient_id\"]\n",
    "    frame = sample[\"img_meta_dict\"].get(\"frame\", \"N/A\")\n",
    "    key = (pid, frame)\n",
    "    grouped_samples[key].append(sample)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (patient_id, frame), samples in grouped_samples.items():\n",
    "        if not (str(patient_id) == \"patient107\" and str(frame) == \"frame01\"):\n",
    "            continue\n",
    "\n",
    "        # Select only desired slices\n",
    "        selected_samples = [s for s in samples if s[\"img_meta_dict\"].get(\"slice_index\", 0) in [0,1,3,5,6,7]]\n",
    "\n",
    "        fig, axes = plt.subplots(len(selected_samples), 5, figsize=(20, 3 * len(selected_samples)))\n",
    "        plt.subplots_adjust(hspace=0.2, wspace=0.05, top=0.95)\n",
    "        fig.suptitle(f\"Patient: {patient_id}, Frame: {frame}\", fontsize=16, fontweight='bold')\n",
    "\n",
    "        if len(selected_samples) == 1:\n",
    "            axes = [axes]  # Ensure iterable if only one row\n",
    "\n",
    "        for row, sample in enumerate(selected_samples):\n",
    "            slice_index = sample[\"img_meta_dict\"].get(\"slice_index\", 0)\n",
    "            img = sample[\"img\"].to(device).unsqueeze(0)\n",
    "            mask = sample[\"mask\"].to(device).unsqueeze(0)\n",
    "\n",
    "            ensemble_models = load_ensemble_models(model_paths, device)\n",
    "            ensemble_model = EnsembleModel(ensemble_models, num_samples_mc=10)\n",
    "\n",
    "            mean_pred, uncertainty = ensemble_model(img)\n",
    "            output_prob = torch.softmax(mean_pred, dim=1)\n",
    "            pred = torch.argmax(output_prob, dim=1, keepdim=True)\n",
    "\n",
    "            img_np = img.squeeze().cpu().numpy()\n",
    "            mask_np = mask.squeeze().cpu().numpy()\n",
    "            pred_np = pred.squeeze().cpu().numpy()\n",
    "            uncertainty_np = uncertainty.squeeze().cpu().numpy().mean(axis=0)\n",
    "\n",
    "            mask_rv = (mask_np == 1).astype(np.uint8)\n",
    "            mask_myo = (mask_np == 2).astype(np.uint8)\n",
    "            mask_lv = (mask_np == 3).astype(np.uint8)\n",
    "            pred_rv = (pred_np == 1).astype(np.uint8)\n",
    "            pred_myo = (pred_np == 2).astype(np.uint8)\n",
    "            pred_lv = (pred_np == 3).astype(np.uint8)\n",
    "\n",
    "            combined_error = (pred_np != mask_np).astype(np.uint8)\n",
    "\n",
    "            row_axes = axes[row]\n",
    "\n",
    "            row_axes[0].imshow(img_np, cmap=\"gray\")\n",
    "            row_axes[0].set_title(f\"Slice {slice_index}\")\n",
    "\n",
    "            row_axes[1].imshow(mask_np, cmap=\"gray\")\n",
    "            row_axes[1].set_title(\"GT Mask\")\n",
    "\n",
    "            row_axes[2].imshow(pred_np, cmap=\"gray\")\n",
    "            row_axes[2].set_title(\"Prediction\")\n",
    "\n",
    "            row_axes[3].imshow(uncertainty_np, cmap=\"hot\")\n",
    "            row_axes[3].set_title(\"Uncertainty\")\n",
    "\n",
    "            row_axes[4].imshow(combined_error, cmap=\"hot\")\n",
    "            row_axes[4].set_title(\"Total Error\")\n",
    "\n",
    "            for ax in row_axes:\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "        save_path = os.path.join(output_dir, f\"Patient_{patient_id}_Frame_{frame}_SLICES_13567.png\")\n",
    "        plt.savefig(save_path,  dpi=200, bbox_inches='tight')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae988d3-6eac-47c4-a9cd-db7f4ccf702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make zip from all patients in test\n",
    "\n",
    "output_dir = \"Patients_uncertainty_error\"\n",
    "# Maak ZIP van de output directory\n",
    "zip_filename = \"Patients_uncertainty_error.zip\"\n",
    "shutil.make_archive(\"Patients_uncertainty_error\", 'zip', output_dir)\n",
    "\n",
    "print(f\"âœ… ZIP-bestand gemaakt: {zip_filename}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
