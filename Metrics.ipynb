{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb0fb0ee-4ac7-42c6-a182-c404eec3f4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nibabel in /home/jovyan/.local/lib/python3.10/site-packages (5.3.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.15.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
      "Requirement already satisfied: medpy in /home/jovyan/.local/lib/python3.10/site-packages (0.5.2)\n",
      "Requirement already satisfied: importlib-resources>=5.12 in /home/jovyan/.local/lib/python3.10/site-packages (from nibabel) (6.5.2)\n",
      "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from nibabel) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from nibabel) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: SimpleITK>=2.1 in /home/jovyan/.local/lib/python3.10/site-packages (from medpy) (2.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nibabel scipy pandas numpy medpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2146e380-e148-4b34-9c56-6c698387e81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics Computation\n",
    "import os\n",
    "from glob import glob\n",
    "import time\n",
    "import re\n",
    "import argparse\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from medpy.metric.binary import hd, dc\n",
    "import numpy as np\n",
    "\n",
    "HEADER = [\"Name\", \"Dice LV\", \"Volume LV\", \"Err LV(ml)\",\n",
    "          \"Dice RV\", \"Volume RV\", \"Err RV(ml)\",\n",
    "          \"Dice MYO\", \"Volume MYO\", \"Err MYO(ml)\"]\n",
    "\n",
    "#\n",
    "# Utils functions used to sort strings into a natural order\n",
    "#\n",
    "def conv_int(i):\n",
    "    return int(i) if i.isdigit() else i\n",
    "\n",
    "def natural_order(sord):\n",
    "    \"\"\"\n",
    "    Sort a (list,tuple) of strings into natural order.\n",
    "    \"\"\"\n",
    "    if isinstance(sord, tuple):\n",
    "        sord = sord[0]\n",
    "    return [conv_int(c) for c in re.split(r'(\\d+)', sord)]\n",
    "\n",
    "#\n",
    "# Utils function to load and save nifti files with the nibabel package\n",
    "#\n",
    "def load_nii(img_path):\n",
    "    \"\"\"\n",
    "    Load a 3D NIfTI file without resizing.\n",
    "    Args:\n",
    "        img_path: Path to the NIfTI file\n",
    "    Returns:\n",
    "        data: Original numpy array\n",
    "        affine: Original affine matrix\n",
    "        header: Original header\n",
    "    \"\"\"\n",
    "    nimg = nib.load(img_path)\n",
    "    data = nimg.get_fdata()\n",
    "    \n",
    "    return data, nimg.affine, nimg.header\n",
    "\n",
    "def save_nii(img_path, data, affine, header):\n",
    "    \"\"\"Save a NIfTI file.\"\"\"\n",
    "    nimg = nib.Nifti1Image(data, affine=affine, header=header)\n",
    "    nimg.to_filename(img_path)\n",
    "\n",
    "#\n",
    "# Metrics computation functions\n",
    "#\n",
    "def metrics(img_gt, img_pred, voxel_size):\n",
    "    \"\"\"\n",
    "    Compute metrics between two segmentation maps.\n",
    "    Both inputs should already be resized to matching dimensions.\n",
    "    \"\"\"\n",
    "    if img_gt.shape != img_pred.shape:\n",
    "        raise ValueError(f\"Shape mismatch: GT {img_gt.shape} vs Pred {img_pred.shape}\")\n",
    "\n",
    "    res = []\n",
    "    for c in [3, 1, 2]:  # Process each class (LV, RV, MYO)\n",
    "        gt_c = np.copy(img_gt)\n",
    "        gt_c[gt_c != c] = 0\n",
    "        pred_c = np.copy(img_pred)\n",
    "        pred_c[pred_c != c] = 0\n",
    "\n",
    "        # Clip and compute metrics\n",
    "        gt_c = np.clip(gt_c, 0, 1)\n",
    "        pred_c = np.clip(pred_c, 0, 1)\n",
    "\n",
    "        dice = dc(gt_c, pred_c)\n",
    "        volpred = pred_c.sum() * np.prod(voxel_size) / 1000.\n",
    "        volgt = gt_c.sum() * np.prod(voxel_size) / 1000.\n",
    "\n",
    "        res += [dice, volpred, volpred-volgt]\n",
    "\n",
    "    return res\n",
    "\n",
    "def compute_metrics_on_files(path_gt, path_pred):\n",
    "    \"\"\"Compute metrics for a single pair of files.\"\"\"\n",
    "    gt, _, header = load_nii(path_gt)\n",
    "    pred, _, _ = load_nii(path_pred)\n",
    "    zooms = header.get_zooms()\n",
    "\n",
    "    name = os.path.basename(path_gt).split('.')[0]\n",
    "    res = metrics(gt, pred, zooms)\n",
    "    res = [\"{:.3f}\".format(r) for r in res]\n",
    "\n",
    "    formatting = \"{:>14}, {:>7}, {:>9}, {:>10}, {:>7}, {:>9}, {:>10}, {:>8}, {:>10}, {:>11}\"\n",
    "    print(formatting.format(*HEADER))\n",
    "    print(formatting.format(name, *res))\n",
    "\n",
    "def compute_metrics_on_directories(dir_gt, dir_pred):\n",
    "    \"\"\"Batch process all files in directories.\"\"\"\n",
    "    lst_gt = sorted(glob(os.path.join(dir_gt, '*')), key=natural_order)\n",
    "    lst_pred = sorted(glob(os.path.join(dir_pred, '*')), key=natural_order)\n",
    "\n",
    "    res = []\n",
    "    for p_gt, p_pred in zip(lst_gt, lst_pred):\n",
    "        if os.path.basename(p_gt) != os.path.basename(p_pred):\n",
    "            raise ValueError(f\"Name mismatch: {os.path.basename(p_gt)} vs {os.path.basename(p_pred)}\")\n",
    "\n",
    "        gt, _, header = load_nii(p_gt)\n",
    "        pred, _, _ = load_nii(p_pred)\n",
    "        zooms = header.get_zooms()\n",
    "        res.append(metrics(gt, pred, zooms))\n",
    "\n",
    "    lst_name_gt = [os.path.basename(gt).split(\".\")[0] for gt in lst_gt]\n",
    "    res = [[n,] + r for r, n in zip(res, lst_name_gt)]\n",
    "    df = pd.DataFrame(res, columns=HEADER)\n",
    "    df.to_csv(f\"results_{time.strftime('%Y%m%d_%H%M%S')}.csv\", index=False)\n",
    "\n",
    "def main(path_gt, path_pred):\n",
    "    \"\"\"Entry point for file or directory processing.\"\"\"\n",
    "    if os.path.isfile(path_gt) and os.path.isfile(path_pred):\n",
    "        compute_metrics_on_files(path_gt, path_pred)\n",
    "    elif os.path.isdir(path_gt) and os.path.isdir(path_pred):\n",
    "        compute_metrics_on_directories(path_gt, path_pred)\n",
    "    else:\n",
    "        raise ValueError(\"Paths must be both files or both directories\")\n",
    "\n",
    "# Define paths to the ground truth and predictions\n",
    "gt_path = \"database/testing/segmentation\"   # Change this to your ground truth folder\n",
    "pred_path = \"Segmentations_ensemble\"  # Change this to your predictions folder\n",
    "\n",
    "# Run the evaluation\n",
    "main(gt_path, pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841df756-0ef3-40a4-ba88-84ebf888a18e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
